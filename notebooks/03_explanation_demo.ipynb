{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CausalShapGNN Explanation Demo\n",
    "\n",
    "This notebook demonstrates the multi-granularity explanations generated by CausalShapGNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import get_default_config\n",
    "from data import DataPreprocessor, BipartiteGraphProcessor\n",
    "from models import CausalShapGNN\n",
    "from explainers import FeatureShapley, PathShapley, UserProfileShapley\n",
    "from explainers import ExplanationReport, ExplanationVisualizer\n",
    "from utils import set_seed\n",
    "\n",
    "set_seed(42)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "preprocessor = DataPreprocessor('../data', 'movielens-100k')\n",
    "graph_data = preprocessor.load_data()\n",
    "\n",
    "# Setup config\n",
    "config = get_default_config()\n",
    "config['n_users'] = graph_data.n_users\n",
    "config['n_items'] = graph_data.n_items\n",
    "config['embed_dim'] = 64\n",
    "config['n_factors'] = 4\n",
    "config['n_layers'] = 3\n",
    "\n",
    "# Process graph\n",
    "graph_processor = BipartiteGraphProcessor(\n",
    "    graph_data.n_users, graph_data.n_items,\n",
    "    graph_data.train_interactions, device\n",
    ")\n",
    "\n",
    "# Initialize model (in practice, load trained checkpoint)\n",
    "model = CausalShapGNN(config, device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 42\n",
    "\n",
    "with torch.no_grad():\n",
    "    user_emb, item_emb, _ = model(graph_processor.norm_adj, use_causal_only=True)\n",
    "\n",
    "scores = torch.matmul(user_emb[user_id], item_emb.t())\n",
    "\n",
    "# Mask training items\n",
    "train_items = list(graph_processor.train_user_items[user_id])\n",
    "if train_items:\n",
    "    scores[train_items] = -float('inf')\n",
    "\n",
    "_, top_items = torch.topk(scores, 10)\n",
    "top_items = top_items.cpu().numpy().tolist()\n",
    "\n",
    "print(f\"Top 10 recommendations for User {user_id}:\")\n",
    "for i, item in enumerate(top_items):\n",
    "    print(f\"  {i+1}. Item {item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature-Level Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_explainer = FeatureShapley(model, device)\n",
    "feature_explainer._compute_population_means(user_emb, item_emb)\n",
    "\n",
    "item_idx = top_items[0]\n",
    "shapley = feature_explainer.compute(user_id, item_idx, user_emb, item_emb)\n",
    "\n",
    "factor_names = ['Genre', 'Recency', 'Quality', 'Social']\n",
    "\n",
    "print(f\"\\nFeature-level explanation for Item {item_idx}:\")\n",
    "for name, value in zip(factor_names, shapley):\n",
    "    print(f\"  {name}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "visualizer = ExplanationVisualizer(factor_names)\n",
    "\n",
    "colors = ['green' if v >= 0 else 'red' for v in shapley]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.barh(factor_names, shapley, color=colors)\n",
    "plt.xlabel('Shapley Value')\n",
    "plt.title(f'Factor Contributions for Item {item_idx}')\n",
    "plt.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. User Profile Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_explainer = UserProfileShapley(feature_explainer)\n",
    "user_profile = profile_explainer.compute(user_id, top_items, user_emb, item_emb)\n",
    "\n",
    "report_generator = ExplanationReport(model, device, factor_names)\n",
    "report = report_generator.generate_user_profile_report(user_id, user_profile, top_items)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare Explanations Across Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get explanations for top 5 items\n",
    "explanations = []\n",
    "for item_idx in top_items[:5]:\n",
    "    shapley = feature_explainer.compute(user_id, item_idx, user_emb, item_emb)\n",
    "    explanations.append({'item_idx': item_idx, 'feature_shapley': shapley})\n",
    "\n",
    "# Create heatmap\n",
    "shapley_matrix = np.array([e['feature_shapley'] for e in explanations])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(shapley_matrix, cmap='RdBu_r', aspect='auto')\n",
    "plt.colorbar(label='Shapley Value')\n",
    "plt.xticks(range(len(factor_names)), factor_names)\n",
    "plt.yticks(range(len(explanations)), [f\"Item {e['item_idx']}\" for e in explanations])\n",
    "plt.title('Factor Contributions Across Recommendations')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}